## 概念

同步指的是一个行为，当执行IO操作的时候，在代码层面我们需要主动去等待结果，直到结果返回。

而阻塞指的是一种状态，当执行IO操作的时候，线程处于挂起状态，就是该线程没有执行了。

所以同步不是阻塞，同步也可以是非阻塞的，比如我们在执行同步代码块的时候，线程可以不阻塞而是一直在后台运行。

同步描述的是一种行为，而阻塞描述的是一种状态（异步与非阻塞也是如此）。



异步是区别于同步的，我们知道，程序在执行IO操作时候，如果是同步代码块，程序会一直处于阻塞状态，也就是必须等待该IO操作返回出结果，程序才能继续执行下去。

如果采用了异步的实现方式，那么当执行IO操作的时候程序可以不用等待，还可以继续执行其他代码块，比如执行其他异步的IO操作。

假设该程序是多线程的，如果采用同步的实现方式，那么该程序就会在这一个线程上面等待，并且其他的线程也必须等待该线程的完成。

采用异步的方式，当程序执行IO操作的时候，程序可以去执行其他线程的代码，不用在这里一直等着，当有结果返回的时候，程序再回来执行该代码块。



将同步的代码换成异步的代码能解决一些性能上的问题，但是并不能解决阻塞调用所带来的瓶颈，即使在代码层面已经优化得非常好了，也不能带来质的提升。

这是因为一个系统的性能好坏，往往由最弱的那一环来决定，如果在服务端进行阻塞调用的时候有大部分线程都处于挂起状态，即使程序采用异步调用也不能解决问题。



## 多线程

传统的Java Web框架所采用的服务器通常是Tomcat，而Tomcat所采用的就是多线程的方式。

当有请求接入服务器的时候，Tomcat会为每一个请求连接分配一个线程。

当请求不是很多的时候，系统是不会出现什么问题的，一旦请求数多于Tomcat所能分配的最大线程数时，如果这时有多个请求被阻塞住了，就会出现一些问题。



多线程在执行的时候，只是看上去是同时执行的，因为线程的执行是通过CPU来进行调度的，CPU通过在每个线程之间快速切换，使得其看上去是同时执行的一样。

其实CPU在某一个时间片内只能执行一个线程，当这个线程执行一会儿之后，它就会去执行其他线程。

当CPU从一个线程切换到另一个线程的时候会执行许多操作，主要有如下两个操作：

❑ 保存当前线程的执行上下文；

❑ 载入另外一个线程的执行上下文。

注意，这种切换所产生的开销是不能忽视的，当线程池中的线程有许多被阻塞住了，CPU就会将该线程挂起，去执行别的线程，那么就产生了线程切换。

当切换很频繁的时候，就会消耗大量的资源在切换线程操作上，这就会导致一个后果——采用多线程的实现方式并不优于单线程。



## 协程

协程并不是一个非常新的概念，它早在1963年就已经被提出来了。

协程是一个无优先级的子程序调度组件，允许子程序在特定的地方挂起恢复。

线程包含于进程，协程包含于线程。

只要内存足够，一个线程中可以有任意多个协程，但某一时刻只能有一个协程在运行，多个协程分享该线程分配到的计算机资源。



线程是由操作系统来进行调度的，前面说过，当操作系统切换线程的时候，会产生一定的消耗。

而协程不一样，协程是包含于线程的，也就是说协程是工作在线程之上的，协程的切换可以由程序自己来控制，不需要操作系统去进行调度。这样的话就大大降低了开销。



### 使用协程

```kotlin
import kotlinx.coroutines.GlobalScope
import kotlinx.coroutines.delay
import kotlinx.coroutines.launch

fun main() {
  GlobalScope.launch {
    delay(100L)
    println("Word")
  }
  println("Hello, ")
  Thread.sleep(2000L)
}
```

launch构造了一个协程，该协程内部调用了delay方法，该方法会挂起协程，但是不会阻塞线程，所以在协程延迟1秒的时间段内，线程中的“Hello, ”会被先输出，然后“World! ”才会被输出。



❑ delay只能在协程内部使用，它用于挂起协程，不会阻塞线程；

❑ sleep用来阻塞线程。



launch与runBlocking。这两个函数都会启动一个协程，不同的是，runBlocking为最高级的协程，也就是主协程，launch创建的协程能够在runBlocking中运行（反过来是不行的）。

runBlocking方法仍旧会阻塞当前执行的线程。



```kotlin
import kotlinx.coroutines.delay
import kotlinx.coroutines.launch
import kotlinx.coroutines.runBlocking

suspend fun search() {
  delay(1000L)
  println("World!")
}

fun main() = runBlocking {
  val job = launch {
    search()
  }
  println("Hello, ")
  job.join()
}
```

`job.join` 程序就会一直等待，直到我们启动的协程结束。

**注意，这里的等待是非阻塞式的等待，不会将当前线程挂起。**



用suspend修饰的方法在协程内部使用的时候和普通的方法没什么区别，不同的是**在suspend修饰的方法内部还可以调用其他suspend方法。**

比如，我们在上面的search方法中调用的delay就是一个suspend修饰的方法，这些方法只能在协程内部或者其他suspend方法中执行，不能在普通的方法中执行。



```kotlin
import kotlinx.coroutines.delay
import kotlinx.coroutines.runBlocking

suspend fun searchItemOne(): String {
  delay(1000L)
  return "item-one"
}

suspend fun searchItemTwo(): String {
  delay(1000L)
  return "item-two"
}

fun main() = runBlocking {
  val one = searchItemOne()
  val two = searchItemTwo()
  println("The items is $one and $two")
}
```

在我们执行这两个查询操作的时候，在协程内部，这两个方法其实是顺序执行的，也就是说，先执行searchItemlOne，再执行searchItemlOne，这有点类似我们在11.1.1节中利用Java实现的同步代码。

因为这两个查询操作不会相互依赖，也就是说，第2个查询操作不需要等第1个查询操作完成之后再去执行，它们的关系应该是并行的。



```kotlin
fun main() = runBlocking {
  val one = async { searchItemOne() }
  val two = async { searchItemTwo() }
  println("The items is ${one.await()} and ${two.await()}")
}
```

使用async也相当于创建了一个子协程，它会和其他子协程一样并行工作，与launch不同的是，async会返回一个Deferred对象。



Deferred值是一个非阻塞可取消的future，它是一个带有结果的job。

launch也会返回一个job对象，但是没有返回值。



通过使用async与await我们就实现了异步并行的代码。



## 锁

虽然Kotlin是基于Java改良过来的语言，但是它没有synchronized，取而代之，它使用了@Synchronized注解和synchronized()来实现等同的效果。

```kotlin
package lock

class Shop {
  val goods = hashMapOf<Long, Int>()

  init {
    goods.put(1, 10)
    goods.put(2, 15)
  }

  @Synchronized
  fun buydGoods(id: Long) {
    val stock = goods.getValue(id)
    goods.put(id, stock - 1)
  }

  fun buyGoods2(id: Long) {
    synchronized(this) {
      val stock = goods.getValue(id)
      goods.put(id, stock - 1)
    }
  }
}
```

在Kotlin中，**使用@Synchronized注解来声明一个同步方法，另外使用synchronized()来对一个代码块进行加锁。**

你可能不喜欢用synchronized方式来写一个同步代码，因为它在有些时候性能表现很一般。

确实synchronized在并发激烈的情况下，不是一个很好的选择。

但是在实际开发中，我们要根据具体场景来设计方案，比如我们明知并发量不会很大，却一味地追求所谓的高并发，最终只会导致复杂臃肿的设计及众多基本无用的代码。

**软件设计中有一句名言：过早的优化是万恶之源。**

在竞争不是很激烈的情况下，使用synchronized相对来说更加简单，也更加语义化。



Kotlin除了支持Java中synchronized这种并发原语外，也同样支持其他一些并发工具，比如volatile关键字，java.util.concurrent.*下面的并发工具。

当然，Kotlin也做了一些改造，比如volatile关键字在Kotlin中也变成了注解：

```kotlin
@Volatile private var running = false 
```



除了可以用synchronized这种方式来对代码进行同步加锁以外，在Java中还可以用Lock的方式来对代码进行加锁。

```kotlin
val lock: Lock = ReentrantLock()
fun buyGoods3(id: Long) {
  lock.lock()
  try {
    val stock = goods.getValue(id)
    goods.put(id, stock - 1)
  } catch (ex: Exception) {
    println(ex)
  } finally {
    lock.unlock()
  }
}
```

ReentrantLock重入锁，是实现Lock接口的一个类，也是在实际编程中使用频率很高的一个锁，**支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞**。

在java关键字synchronized隐式支持重入性，synchronized通过获取自增，释放自减的方式实现重入。

ReentrantLock支持两种锁：**公平锁**和**非公平锁**。

**何谓公平性，是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求上的绝对时间顺序，满足FIFO**。

ReentrantLock的构造方法无参时是构造非公平锁, false时为非公平锁



**公平锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁则不一定，有可能刚释放锁的线程能再次获取到锁**。导致其他线程永远无法获取到锁，**造成“饥饿”现象**。

公平锁为了保证时间上的绝对顺序，需要频繁的上下文切换，而非公平锁会降低一定的上下文切换，降低性能开销。因此，ReentrantLock默认选择的是非公平锁，则是为了减少一部分上下文切换，**保证了系统更大的吞吐量**。



但是这种写法似乎有如下不好之处：

❑ 若是在同一个类内有多个同步方法，将会竞争同一把锁；

❑ 在加锁之后，编码人员很容易忘记解锁操作；

❑ 重复的模板代码。

kotlin 提供了 `withLock` API

```kotlin
val lock:Lock = ReentrantLock()
val result = lock.withLock {
  // do Something.
}

/**
 * Executes the given [action] under this lock.
 * @return the return value of the action.
 */
@kotlin.internal.InlineOnly
public inline fun <T> Lock.withLock(action: () -> T): T {
    lock()
    try {
        return action()
    } finally {
        unlock()
    }
}
```



## Actor

一个真正的、有状态的并行计算单元——Actor。

Actor这个概念已经存在很久了，它由Carl Hewitt、Peter Bishop及Richard Steiger在1973年的论文中提出，但直到这种概念在Erlang中应用后，才逐渐被大家所熟知。

而且现在Actor模型已经被应用在生产环境中，比如Akka（一个基于Actor模型的并发框架）。

另外很多语言也支持Actor模型，比如Scala、Java，包括Kotlin也内置了Actor模型。



Actor模型所要做的事情很简单：

❑ 用另一种思维来解决并发问题，而不是只有共享内存这一种方式；

❑ 提高锁抽象的程度，尽量不在业务中出现锁，减少因为使用锁出现的问题，比如死锁；

❑ 为解决分布式并发问题提供一种更好的思路。



Actor模型提倡的是：通过通信来实现共享内存，而不是用共享内存来实现通讯。



在Java中我们要去操作共享内存中的数据时，每个线程都需要不断地获取共享内存的监视器锁，然后将操作后的数据暴露给其他线程访问使用，用共享内存来实现各个线程之间的通信。

而在Akka中，我们可以将共享可变的变量作为一个Actor内部的状态，利用Actor模型本身串行处理消息的机制来保证变量的一致性。

当然，要使用该机制也必须满足以下两条原则：

❑ 消息的发送必须先于消息的接收；

❑ 同一个Actor对一条消息的处理先于对下一条消息的处理。



一个是向MailBox中写入消息，一个是从MailBox中读取消息，它们不是一个原子操作，可能会出现一条消息在被写入MailBox中还没结束的时候，就被Actor读取走了，这就有可能出现一些未知的情况。

所以必须保证消息的发送先于消息的接收，简单来说就是消息必须先完整地写入MailBox才能被接收处理。那么MailBox必须是线程安全的。

MailBox是一个存储消息的队列，而且消息只会添加在队列的尾部，取消息是在队列的头部，那么这里可以使用LinkedBlockingDeque来作为MailBox的基础结构，它是基于双向链表实现的，而且也是线程安全的。

但是需要说明的一点是，LinkedBlockingDeque内部还是使用Lock来保证线程安全的。其实还有其他队列也适合这种场景，比如ConcurrentLinkedQueue，它内部使用CAS操作来保证线程安全。

但是Akka并没有采用这两种方案，而是自己实现了一个AbstractNodeQueue，有兴趣的读者可以去看一下源码：https://github.com/akka/akka/blob/master/akka-actor/src/main/java/akka/dispatch/AbstractNodeQueue.java。

从源码可以看出，AbstractNodeQueue是一个功能更加明确的队列，是专门为Actor这种需求所设计的。



## 数据持久化

我们在逻辑上已经将业务分解了，若是最后又回归到数据库单个表的竞争，那么前面所有的花费都是徒劳。

**一般情况下，在系统优化得当的情况下，并发的瓶颈就在于数据库，主要有两方面：**

❑ 数据库的连接和关闭，网络传输需要一定时间；

❑ 一些不恰当的或者事务需要锁表的SQL，如果大量执行会导致数据库执行变慢，甚至崩溃。



当并发激烈的时候会给数据库带来很大的压力，频繁的锁表事务操作不仅会让SQL的执行变慢、失败，还会影响整个系统的吞吐量，甚至引起系统的崩溃。

那么面对这种情况，是否有别的方案能解决这个问题？

我们来试想一下能不能采用读写分离这种思想，最容易想到的是主从数据库。

但是这种方案还是有一些问题，

一来避免不了修改库存时候的并发竞争，

二来数据同步也需要大量的消耗。

其实我们能运用另一种方式来解决这个问题，那就是CQRS（Command Query ResponsibilitySegregation）架构

**主从架构本来就是一种高可用性解决方案，而不是高并发解决方案。**



### CQRS

CQRS是一种命令与查询职责分离的设计原则，简单来说也是一种读写分离的设计方案。

但它与我们普通方式的读写分离有一些区别，主要体现在写方面，它不再是对记录进行不断修改，而是一种事件溯源的思维方式。

举个简单的例子，它跟数据库备份所使用的binlog方案很像，数据库会将有修改状态行为的SQL执行情况一条一条地记录在binlog日志中，利用这些记录便能推导出最终的状态。

事件溯源这个名词听起来可能不好理解，其实它的原理很简单，就是根据一系列事件推导出对象的最新状态。

举个简单的例子，假如你购买一件商品，那么这件商品的库存应该减一，但是你突然又不想买了，进行了退货，那么这时商品库存又要加一。

一来一回商品的库存并没有发生变化，按照普通的方式你会对数据库中的库存来进行状态的修改，但是这种方式要是不借助其他记录，我们将无法知晓在该对象上发生了什么事。

所以比较合理的方式应该是记录每次发生在该对象上的状态变更事件，根据这个事件来推导出对象的最新状态。这便是事件溯源。



事件溯源中最关键的几点：

❑ 以事件为驱动，任何的用户行为都是一种事件，比如上面说的购买商品、退货等；

❑ 存储所有对于对象状态会有影响的事件，这一点至关重要，因为我们在程序恢复或者数据校验的时候都需要它；

❑ 用于查询或者显示的视图数据不一定要持久化，比如我们将对象的状态数据存放在内存中。



聚合顾名思义是一系列对象的集合。

比如一个商家里面有商品、优惠券等，它们的集合就可以看作一个聚合。

而聚合根属于这个聚合中可以被外部访问的元素，比如这里商家便是一个聚合根，经过它我们才能查看它其中的商品、优惠券等。



为什么说理解聚合和聚合根很重要呢？

因为要结合CQRS、事件溯源这些设计，我们就要用一种新的思维模式去设计我们的业务，**只能通过聚合根来操作聚合中其他对象的状态**，比如只能通过商家去修改商品的库存，而不允许直接修改库存。

这么说可能有点抽象，其实很简单，就是你原来可能直接在数据库中更改一下商品的库存便可以了，而现在你需要向商家发一条修改商品库存的信息，然后它会生成一个库存修改事件，最后才会修改好库存（修改聚合里面对象的状态也可以修改数据库中的记录）。

那么本来简单的一个操作反而变复杂了，它有什么益处呢？

我们以传统的方式来试想一下，假设商家修改了商品库存，但是后来发现修改错了，一来可能忘记了修改的内容无法回滚，二来即使可以回滚，付出的代价也是极大的，因为它需要回滚所有与商品库存有关的操作。

数据回滚的操作在现实环境中还是存在的，比如银行、交易所的业务，如果哪一段时间出现了重大异常，可能就需要回滚数据。

而如果通过一个聚合根来修改聚合中对象的状态，那么这一切将会变得容易。

我们会记录聚合所有的状态更改事件，可以根据这些事件恢复到任一时刻聚合的状态。



那么这种方式有什么缺点吗，当然也有，因为需要保存每次修改状态的事件，将会占用大量的存储空间。

而且在进行状态恢复时，需要回放以前所有的事件，这也会有一定的消耗。

当然这个问题我们可以通过引入快照解决。

上面我们更多探讨的是一种设计，可以算是领域驱动设计的一部分。

那么这种设计为什么能改进并发时遇到的问题呢？

前面说到，并发最大的困难就在于对共享资源的竞争，在前一节我们已经试着将竞争的部分进行分解，达到一个适合的单位。

但是某个具体单位的竞争还是可能会激烈，所以尝试着从业务角度进行优化，比如将修改和查询分开。

但是我们并没有使用传统的思维模式来解决这个问题，而是通过引入CQRS架构，结合领域驱动设计来解决这个问题。

比如，我们可以将持久数据和视图数据分开存储，再比如，视图数据可以存在内存数据中，提高查询效率。

另外，通过保存所有的状态更改事件使内存中的数据是可靠的，比如减少库存数量的时候，不必查询数据库中的数据，直接使用内存中的数据即可。

同时，因为事件是不断被添加而且不能修改，所有我们可以选取写效率高的DB来存储事件，比如cassandra。通过这些优化将会提升程序的性能。



相信大家对CQRS以及Event Sourcing这种设计思维应该有所了解了。

那么为什么会讲这种模式呢？

因为它能跟Kotlin以及Actor结合得很好。

CQRS以及Event Sourcing中最重要的两部分就是事件与聚合的划分，首先事件我们可以通过Kotlin的Data class来实现，而将一个Actor看成聚合更是一个完美的应用，每个Actor维护自身的状态，又简洁又高效。



我们有必要持久化状态更改事件的机制。

Akka为我们提供了简单又高效的方式，那就是PersistenceActor。

顾名思义，PersistenceActor就是支持持久化的Actor，也就是说它的状态是可靠的。



